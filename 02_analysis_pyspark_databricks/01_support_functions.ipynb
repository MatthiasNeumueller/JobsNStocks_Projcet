{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9611be5a-9b0e-4e9d-8acf-38c3af343c66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from psycopg2.extensions import AsIs\n",
    "from psycopg2 import extras\n",
    "from psycopg2 import sql\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1d68980e-2838-4d42-afca-0c4de5895fe2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def get_companies_listed_on_wiener_borse():\n",
    "    \"\"\"\n",
    "     reads all companies with isin number that can be traded at the vienna stock exchange\n",
    "     paramters: None\n",
    "     return: dataFrame with companies\n",
    "    \"\"\"\n",
    "    url_companies = \"https://www.wienerborse.at/listing/aktien/unternehmensliste/\"\n",
    "    response = requests.get(url_companies)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tags = soup.find_all(\"tr\")\n",
    "    number_companies = int(tags[-1].attrs[\"data-key\"])\n",
    "    stock_companies = pd.DataFrame({\"isin\" : [], \"name\" : [], \"country\" : []})\n",
    "    for l in range(number_companies+1):\n",
    "        result = soup.findAll(\"tr\", {\"data-key\" : l})\n",
    "        isin = result[0].contents[0].text\n",
    "        name = result[0].contents[1].text\n",
    "        country = result[0].contents[2].text\n",
    "        stock_companies = stock_companies.append({\"isin\" : isin, \"name\" : name, \"country\" : country}, ignore_index=True)\n",
    "    return stock_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d989d198-515e-438e-8db0-d999cf09c814",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    removes punctuation from a string and makes all lower case\n",
    "    paramters: string\n",
    "    return: same sting but all smaller case, no punctuation and no redundant whitespaces \n",
    "    \"\"\"\n",
    "    text = re.sub(r'_',' ',text)\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = re.sub(r'[\\n]',' ',text)\n",
    "    return text.lower().lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3dde196b-d3b2-46e4-bd9c-06ca1fd1a51b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def read_keywords_wordCount():\n",
    "    \"\"\"\n",
    "    reads and provides a list of keywords that should be displayed (e.g., in a word count)\n",
    "    paramters: None\n",
    "    return: list of keywords\n",
    "    \"\"\"\n",
    "    path = \"/dbfs/FileStore/shared_uploads/ds21m031@codingmohgmail.onmicrosoft.com/ds_keywords.txt\"\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.read()\n",
    "    return re.findall(r'[a-z]+',lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e3d26808-d45f-49e8-b576-8ecfe67bbea5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def do_wordCount(x, keywords):\n",
    "    \"\"\"\n",
    "    performs word count on an rdd \n",
    "    paramters: an df with multiple strings, set of relevant keywords\n",
    "    return: pandas Dataframe in which each word is associated with the number it was encountered\n",
    "    \"\"\"\n",
    "    return     (x.rdd\n",
    "                .flatMap(lambda x: x[0].split())\n",
    "                .filter(lambda x: x != \"\")\n",
    "                .map(lambda x: (x,1))\n",
    "                .reduceByKey(lambda a,b : a+b) \n",
    "                .filter(lambda x: x[0] in keywords)\n",
    "                .toDF()\n",
    "                .toPandas()\n",
    "                .rename(columns={'_1':'word', '_2' : 'count'})\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "99905bb3-efa1-4b26-96d0-321f8353b049",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def transform_data_lm(data):\n",
    "    \"\"\" Transforms pyspark dataframe for use in LM\"\"\"\n",
    "#    return data.rdd.map(lambda r: [Vectors.dense(r[:-2]), r[-1] ]).toDF(['features','label'])\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[0]), r[1] ]).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a4fb7414-811f-405d-a76b-1e45c7728c5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def calculate_LM_per_index(data):\n",
    "    \"\"\" \n",
    "    Calculates a linear model for each index in data set\n",
    "    Input: pyspark data frame - cloumns are indexes; last two columns are for the date in datetime and int format\n",
    "    Output: Pandas DF with LM coefficients per index    \n",
    "    \"\"\"\n",
    "    stock_data = pd.DataFrame({\"isin\" : [], \"coefficient\" : [], \"intersept\" : []})\n",
    "    lr = LinearRegression(fitIntercept=True, maxIter = 100)\n",
    "\n",
    "    for col in data.columns[:-2]:\n",
    "        \"\"\"For each index calculate linear model\"\"\"\n",
    "    #    print(col)\n",
    "        dataLM = transform_data_lm( data.select(col, \"date_ts\") )\n",
    "        lrModel = lr.fit(dataLM)\n",
    "        # Turn coordination system\n",
    "        stock_data = stock_data.append({\"isin\" : col , \"coefficient\" : 1 / lrModel.coefficients.values[0], \"intersept\" : - lrModel.intercept / lrModel.coefficients.values[0]} , ignore_index=True)\n",
    "    #    print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "    #    print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "    #    summary = lrModel.summary\n",
    "    #    print(\"RMSE: %f\" % summary.rootMeanSquaredError)\n",
    "    #    print(\"r2: %f\" % summary.r2)\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7ee600c1-3816-4626-aaa3-2b5e1de9eead",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "def adjust_string_for_matching(word):\n",
    "    \"\"\"\n",
    "    Takes a string as input and manupulates it for a more efficient matching of \n",
    "    company names\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'international','',word)\n",
    "    word = re.sub(r'pharmaceuticals','',word)\n",
    "    word = re.sub(r'pharma','',word)\n",
    "    word = re.sub(r' ag$','',word)\n",
    "    word = re.sub(r' se$','',word)\n",
    "    word = re.sub(r'group','',word)\n",
    "    word = re.sub(r'corporation','',word)\n",
    "    word = re.sub(r'inc\\.{1}','',word)\n",
    "    return word\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4c488847-5e06-49ee-8539-5f7b380cc8db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "def find_best_match(company, possibleMatches, cut_off_score): \n",
    "    \"\"\"\n",
    "    for a given company (string) this function provides the best match from the list possibleMatches\n",
    "    input: company (string), possibleMatches list of strings \n",
    "    output: string from possibleMathes with the best similarity score\n",
    "    \"\"\"\n",
    " #   matches = [(i, fuzz.ratio(company.iloc[0].lower(), i.lower())) for i in possibleMatches ]\n",
    "    matches2 = [(i, fuzz.ratio(adjust_string_for_matching(company.iloc[0]), adjust_string_for_matching(i))) for i in possibleMatches ]\n",
    "    \n",
    " #   bestFit = max(matches,key= lambda x: x[1])\n",
    "    bestFit2 = max(matches2,key= lambda x: x[1])\n",
    "    if bestFit2[1] > cut_off_score:\n",
    "  #      print(\"input {}, match_1 {}, score_1 {}, match_2 {}, score_2 {}\".format(company.iloc[0], bestFit[0], bestFit[1], bestFit2[0], bestFit2[1]))\n",
    "        print(\"input {}, match {}, score {}\".format(company.iloc[0], bestFit2[0], bestFit2[1]))\n",
    "        return bestFit2[0]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e72365d2-906e-471f-8d6d-7af5a1498d87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def geo_coder(address):\n",
    "    \"\"\"\n",
    "    geo code job location\n",
    "    input: address string\n",
    "    output longitude and latitude\n",
    "    !!max number of requests is limited\n",
    "    \"\"\"\n",
    "    url = 'http://open.mapquestapi.com/geocoding/v1/address'\n",
    "    params = {'key': ' \tXHd8D8B7BHYI9MPhOYmJ36YAlhNegD4J', 'location': address}\n",
    "    r = requests.get(url, params=params)\n",
    "    r2 = r.json()[\"results\"][0][\"locations\"][0]['latLng']\n",
    "    return [r2['lng'], r2['lat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2b004ea4-b041-495a-ad32-5de67e92200d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "def read_stock_data(indexList, start, end, ss):\n",
    "    \"\"\"\n",
    "    reads stock data from yfinance api\n",
    "    input: list of relevant isin numbers, start date, end date, spark session\n",
    "    output: pyspark dataframe in the provided spark session\n",
    "    \"\"\"\n",
    "    df = yf.download(indexList, start, end)[\"Close\"] \n",
    "    df[\"date\"] = df.index\n",
    "    return ss.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "94b9be71-f4cd-4047-97b5-f367d9860c9e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def read_list_aktienfinder():\n",
    "    \"\"\"\n",
    "     reads csv from aktienfinder\n",
    "     paramters: None\n",
    "     return: dataFrame with companies\n",
    "    \"\"\"\n",
    "    path = \"/dbfs/FileStore/shared_uploads/ds21m031@codingmohgmail.onmicrosoft.com/companies_aktienfinder.csv\"\n",
    "    return pd.read_csv(path, names = [\"isin\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c5f51810-8ca6-4c06-85ea-ea75ad67274a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def write_to_postgres(df):\n",
    "    \"\"\"\n",
    "    no jdbc driver available on databricks\n",
    "    \"\"\"\n",
    "    (df.write.format(\"jdbc\")\n",
    "     .option(\"url\", \"jdbc:postgresql://dsc-inf.postgres.database.azure.com:5432/nyt_import\")\n",
    "     .option(\"driver\", \"org.postgresql.Driver\")\n",
    "     .option(\"dbtable\", \"ds21_b1_jobs_result\")\n",
    "     .option(\"user\", \"ds21m031\")\n",
    "     .option(\"password\", \"surf1234\")\n",
    "     .option(\"mode\", \"overwrite\")\n",
    "     .save()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "97ee5a4b-26de-4d4b-9153-e05791297954",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def insert_job_result_to_postgres(df, params, tableName):\n",
    "    \"\"\" \n",
    "    insert result of job analysis in to postgres db \n",
    "    input pyspark dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    print(tableName)\n",
    "    sql_insert = '''INSERT INTO %s \n",
    "            (company_name_ad ,\n",
    "            company_name_stock ,\n",
    "            isin ,\n",
    "            description ,\n",
    "            description_clean ,\n",
    "            title ,\n",
    "            salary ,\n",
    "            schedule ,\n",
    "            date_loaded ,\n",
    "            lm_coefficint ,\n",
    "            lm_intersept ,\n",
    "            city ,\n",
    "            country ,\n",
    "            longitude ,\n",
    "            latitude ,\n",
    "            platform)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);'''\n",
    "    sql_drop =   \"DROP TABLE IF EXISTS %s;\"\n",
    "    sql_create = ''' CREATE TABLE IF NOT EXISTS %s   \n",
    "            (id serial UNIQUE, \n",
    "            company_name_ad text,\n",
    "            company_name_stock text,\n",
    "            isin text,\n",
    "            description text,\n",
    "            description_clean text,\n",
    "            title text,\n",
    "            salary text,\n",
    "            schedule text,\n",
    "            date_loaded date,\n",
    "            lm_coefficint real,\n",
    "            lm_intersept real,\n",
    "            city text,\n",
    "            country text,\n",
    "            longitude real,\n",
    "            latitude real,\n",
    "            platform text, \n",
    "            created_at TIMESTAMPTZ NOT NULL DEFAULT NOW());\n",
    "        '''\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=params['host'],\n",
    "                        port=params['port'],\n",
    "                        database=params['database'],\n",
    "                        user=params[\"user\"],\n",
    "                        password=params[\"pass\"]) # connect to the PostgreSQL database\n",
    "        cur = conn.cursor()               # create a new cursor \n",
    "        cur.execute(sql_drop, (AsIs(tableName),))\n",
    "        cur.execute(sql_create, (AsIs(tableName),))\n",
    "\n",
    "        \n",
    "        for row in df.collect(): #!!!!!!!!!!!! TEMPORARY SOLUTION AS DRIVER NOR AVAILABLE\n",
    "            tup = [i for i in row]\n",
    "            tup.insert(0, AsIs(tableName))\n",
    "            cur.execute(sql_insert, tup)\n",
    "\n",
    "        conn.commit()                     # commit the changes to the database\n",
    "        cur.close()                       # close communication with the database\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "            \n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1334e1de-d83d-4f14-8ea8-5415c4a02101",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "def insert_word_count_to_postgres(df_list, params, tableName):\n",
    "    \"\"\" \n",
    "    insert result of word count into postgres db \n",
    "    input list of pandas dataframes, paramters for connecting to db, tablename \n",
    "    \"\"\"\n",
    "    url = f\"postgresql://{params['user']}:{params['pass']}@{params['host']}:{params['port']}/{params['database']}\"\n",
    "    engine = create_engine(url)\n",
    "    \n",
    "    sql_drop =   \"DROP TABLE IF EXISTS %s;\"\n",
    "    engine.execute(sql_drop, (AsIs(tableName), ))\n",
    "    \n",
    "    \n",
    "    for table in df_list:\n",
    "        table['Timestamp'] = datetime.now()\n",
    "        table.to_sql(tableName, engine, if_exists = \"append\", index = False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "supportFunctions",
   "notebookOrigID": 870908007318636,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
